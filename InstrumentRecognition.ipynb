{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BRAINSTORM\n",
    "- IRMAS - predominant instrument recognition\n",
    "- single instrument: included in part 4 of instrument recog doc\n",
    "\n",
    "Strategy:\n",
    "\n",
    "1) create spectograms\n",
    "2) pass into NN\n",
    "3) see results and go from there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what I actually want is two np arrays X and y that preserve mapping of spec to label\n",
    "\n",
    "#helper function getSpecLab(filename)\n",
    "\n",
    "import os\n",
    "\n",
    "def getSpecAndLab(filename):\n",
    "    y, sr = librosa.load(filename)\n",
    "    spec = librosa.feature.melspectrogram(y=y)\n",
    "    label = filename[6:9]\n",
    "    return spec, label\n",
    "\n",
    "\n",
    "def createXyFromDir(root):\n",
    "    specs = []\n",
    "    labels = []\n",
    "\n",
    "    percent = 0\n",
    "    total = len(os.listdir(root)) - 1\n",
    "\n",
    "    for dir in os.listdir(root):\n",
    "        d = os.path.join(root, dir).replace(\"\\\\\",\"/\")\n",
    "        # checking if it is a dir\n",
    "        if os.path.isdir(d):\n",
    "            print(f'Now processing {d}, {(percent/total * 100):.2f}% complete')\n",
    "            for file in os.listdir(d):\n",
    "                f = os.path.join(d, file).replace(\"\\\\\",\"/\")\n",
    "                spec, label = getSpecAndLab(f)\n",
    "                specs.append(spec)\n",
    "                labels.append(label)\n",
    "        percent+=1\n",
    "                \n",
    "    return (np.array(specs), np.array(labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec shape: (128, 130), label: cel\n"
     ]
    }
   ],
   "source": [
    "testspec, testlabel = getSpecAndLab('Audio\\cel\\[cel][cla]0001__1.wav')\n",
    "\n",
    "print(f'spec shape: {testspec.shape}, label: {testlabel}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing Audio/cel, 0.00% complete\n",
      "Now processing Audio/cla, 9.09% complete\n",
      "Now processing Audio/flu, 18.18% complete\n",
      "Now processing Audio/gac, 27.27% complete\n",
      "Now processing Audio/gel, 36.36% complete\n",
      "Now processing Audio/org, 45.45% complete\n",
      "Now processing Audio/pia, 54.55% complete\n",
      "Now processing Audio/sax, 72.73% complete\n",
      "Now processing Audio/tru, 81.82% complete\n",
      "Now processing Audio/vio, 90.91% complete\n",
      "Now processing Audio/voi, 100.00% complete\n"
     ]
    }
   ],
   "source": [
    "root = 'Audio'\n",
    "\n",
    "X, y = createXyFromDir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6705, 128, 130) (6705,)\n",
      "(6705, 128, 130, 1) (6705,)\n",
      "voi\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "\n",
    "X = X.reshape(6705, 128, 130, 1)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "print(y[6000])\n",
    "\n",
    "#now want to get square CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6705,)\n",
      "(6705, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "y_transformed = encoder.fit_transform(y.reshape(-1,1)).toarray()\n",
    "\n",
    "print(y_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_transformed, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now test on simple model\n",
    "\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(128,130,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, padding='same'))\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, padding='same'))\n",
    "model.add(Dropout(0.45))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(Conv2D(256, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(11, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "170/170 [==============================] - 263s 2s/step - loss: 2.4442 - accuracy: 0.1600 - val_loss: 2.2324 - val_accuracy: 0.2450\n",
      "Epoch 2/75\n",
      "170/170 [==============================] - 249s 1s/step - loss: 2.1709 - accuracy: 0.2483 - val_loss: 2.0307 - val_accuracy: 0.2848\n",
      "Epoch 3/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 2.0519 - accuracy: 0.3002 - val_loss: 1.9626 - val_accuracy: 0.3129\n",
      "Epoch 4/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 1.9681 - accuracy: 0.3344 - val_loss: 1.8942 - val_accuracy: 0.3394\n",
      "Epoch 5/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.9012 - accuracy: 0.3630 - val_loss: 1.8480 - val_accuracy: 0.3758\n",
      "Epoch 6/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.8581 - accuracy: 0.3707 - val_loss: 1.7351 - val_accuracy: 0.4089\n",
      "Epoch 7/75\n",
      "170/170 [==============================] - 246s 1s/step - loss: 1.7890 - accuracy: 0.3948 - val_loss: 1.8519 - val_accuracy: 0.3725\n",
      "Epoch 8/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 1.7358 - accuracy: 0.4123 - val_loss: 1.6706 - val_accuracy: 0.4189\n",
      "Epoch 9/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.6844 - accuracy: 0.4405 - val_loss: 1.5711 - val_accuracy: 0.4685\n",
      "Epoch 10/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.6648 - accuracy: 0.4435 - val_loss: 1.7529 - val_accuracy: 0.4139\n",
      "Epoch 11/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.6346 - accuracy: 0.4554 - val_loss: 1.5044 - val_accuracy: 0.5033\n",
      "Epoch 12/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.5260 - accuracy: 0.4961 - val_loss: 1.4821 - val_accuracy: 0.5066\n",
      "Epoch 13/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 1.4617 - accuracy: 0.5131 - val_loss: 1.4272 - val_accuracy: 0.5050\n",
      "Epoch 14/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.4267 - accuracy: 0.5280 - val_loss: 1.3033 - val_accuracy: 0.5579\n",
      "Epoch 15/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.4231 - accuracy: 0.5260 - val_loss: 1.3379 - val_accuracy: 0.5613\n",
      "Epoch 16/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 1.3429 - accuracy: 0.5475 - val_loss: 1.2826 - val_accuracy: 0.5695\n",
      "Epoch 17/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.3194 - accuracy: 0.5610 - val_loss: 1.2539 - val_accuracy: 0.5844\n",
      "Epoch 18/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.2990 - accuracy: 0.5669 - val_loss: 1.1998 - val_accuracy: 0.6043\n",
      "Epoch 19/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.2528 - accuracy: 0.5770 - val_loss: 1.3015 - val_accuracy: 0.5546\n",
      "Epoch 20/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 1.2253 - accuracy: 0.5847 - val_loss: 1.2091 - val_accuracy: 0.5911\n",
      "Epoch 21/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 1.2060 - accuracy: 0.5976 - val_loss: 1.1925 - val_accuracy: 0.5993\n",
      "Epoch 22/75\n",
      "170/170 [==============================] - 249s 1s/step - loss: 1.1856 - accuracy: 0.6050 - val_loss: 1.2014 - val_accuracy: 0.5894\n",
      "Epoch 23/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 1.1650 - accuracy: 0.6081 - val_loss: 1.1561 - val_accuracy: 0.6192\n",
      "Epoch 24/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 1.1502 - accuracy: 0.6236 - val_loss: 1.2076 - val_accuracy: 0.6275\n",
      "Epoch 25/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.1230 - accuracy: 0.6319 - val_loss: 1.2919 - val_accuracy: 0.5646\n",
      "Epoch 26/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.1092 - accuracy: 0.6210 - val_loss: 1.1360 - val_accuracy: 0.6291\n",
      "Epoch 27/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.0910 - accuracy: 0.6411 - val_loss: 1.1098 - val_accuracy: 0.6258\n",
      "Epoch 28/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.0659 - accuracy: 0.6398 - val_loss: 1.1239 - val_accuracy: 0.6225\n",
      "Epoch 29/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.0473 - accuracy: 0.6440 - val_loss: 1.2421 - val_accuracy: 0.6076\n",
      "Epoch 30/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.0715 - accuracy: 0.6455 - val_loss: 1.1699 - val_accuracy: 0.6175\n",
      "Epoch 31/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.0248 - accuracy: 0.6576 - val_loss: 1.0893 - val_accuracy: 0.6440\n",
      "Epoch 32/75\n",
      "170/170 [==============================] - 245s 1s/step - loss: 1.0272 - accuracy: 0.6510 - val_loss: 1.0895 - val_accuracy: 0.6523\n",
      "Epoch 33/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.0053 - accuracy: 0.6600 - val_loss: 1.1212 - val_accuracy: 0.6507\n",
      "Epoch 34/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 1.0119 - accuracy: 0.6602 - val_loss: 1.0590 - val_accuracy: 0.6490\n",
      "Epoch 35/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.9387 - accuracy: 0.6840 - val_loss: 1.0101 - val_accuracy: 0.6705\n",
      "Epoch 36/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 0.9567 - accuracy: 0.6794 - val_loss: 1.0400 - val_accuracy: 0.6689\n",
      "Epoch 37/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 0.9604 - accuracy: 0.6810 - val_loss: 1.1176 - val_accuracy: 0.6440\n",
      "Epoch 38/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 0.9393 - accuracy: 0.6808 - val_loss: 1.0735 - val_accuracy: 0.6656\n",
      "Epoch 39/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.9463 - accuracy: 0.6843 - val_loss: 1.1067 - val_accuracy: 0.6523\n",
      "Epoch 40/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.9615 - accuracy: 0.6786 - val_loss: 1.0916 - val_accuracy: 0.6623\n",
      "Epoch 41/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 0.9340 - accuracy: 0.6869 - val_loss: 1.1779 - val_accuracy: 0.6440\n",
      "Epoch 42/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.8974 - accuracy: 0.7028 - val_loss: 1.0559 - val_accuracy: 0.6838\n",
      "Epoch 43/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.8816 - accuracy: 0.7029 - val_loss: 1.1053 - val_accuracy: 0.6507\n",
      "Epoch 44/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.8643 - accuracy: 0.6976 - val_loss: 1.0255 - val_accuracy: 0.6656\n",
      "Epoch 45/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.9172 - accuracy: 0.6902 - val_loss: 0.9925 - val_accuracy: 0.6788\n",
      "Epoch 46/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.8571 - accuracy: 0.7094 - val_loss: 1.1150 - val_accuracy: 0.6556\n",
      "Epoch 47/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.8717 - accuracy: 0.7077 - val_loss: 1.0391 - val_accuracy: 0.6556\n",
      "Epoch 48/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 0.8376 - accuracy: 0.7252 - val_loss: 1.1837 - val_accuracy: 0.6374\n",
      "Epoch 49/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.8161 - accuracy: 0.7210 - val_loss: 1.1711 - val_accuracy: 0.6689\n",
      "Epoch 50/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.8420 - accuracy: 0.7212 - val_loss: 1.1752 - val_accuracy: 0.6556\n",
      "Epoch 51/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.8433 - accuracy: 0.7195 - val_loss: 1.1188 - val_accuracy: 0.6854\n",
      "Epoch 52/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.8129 - accuracy: 0.7287 - val_loss: 1.0500 - val_accuracy: 0.6705\n",
      "Epoch 53/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.8486 - accuracy: 0.7138 - val_loss: 1.1043 - val_accuracy: 0.6772\n",
      "Epoch 54/75\n",
      "170/170 [==============================] - 246s 1s/step - loss: 0.8248 - accuracy: 0.7186 - val_loss: 1.0567 - val_accuracy: 0.6772\n",
      "Epoch 55/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.8084 - accuracy: 0.7232 - val_loss: 0.9649 - val_accuracy: 0.6954\n",
      "Epoch 56/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.8236 - accuracy: 0.7274 - val_loss: 1.0127 - val_accuracy: 0.6705\n",
      "Epoch 57/75\n",
      "170/170 [==============================] - 246s 1s/step - loss: 0.7703 - accuracy: 0.7379 - val_loss: 1.0927 - val_accuracy: 0.6573\n",
      "Epoch 58/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.7876 - accuracy: 0.7354 - val_loss: 1.1289 - val_accuracy: 0.6623\n",
      "Epoch 59/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.7718 - accuracy: 0.7374 - val_loss: 1.1070 - val_accuracy: 0.6904\n",
      "Epoch 60/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 0.7555 - accuracy: 0.7455 - val_loss: 0.9899 - val_accuracy: 0.7003\n",
      "Epoch 61/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.7648 - accuracy: 0.7424 - val_loss: 1.0471 - val_accuracy: 0.6854\n",
      "Epoch 62/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 0.7228 - accuracy: 0.7516 - val_loss: 1.0840 - val_accuracy: 0.6937\n",
      "Epoch 63/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 0.7370 - accuracy: 0.7558 - val_loss: 1.0920 - val_accuracy: 0.6838\n",
      "Epoch 64/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 0.7080 - accuracy: 0.7615 - val_loss: 1.0503 - val_accuracy: 0.6755\n",
      "Epoch 65/75\n",
      "170/170 [==============================] - 243s 1s/step - loss: 0.7586 - accuracy: 0.7449 - val_loss: 1.0576 - val_accuracy: 0.6921\n",
      "Epoch 66/75\n",
      "170/170 [==============================] - 249s 1s/step - loss: 0.7169 - accuracy: 0.7589 - val_loss: 1.0673 - val_accuracy: 0.6887\n",
      "Epoch 67/75\n",
      "170/170 [==============================] - 251s 1s/step - loss: 0.7511 - accuracy: 0.7425 - val_loss: 1.1252 - val_accuracy: 0.6871\n",
      "Epoch 68/75\n",
      "170/170 [==============================] - 254s 1s/step - loss: 0.7381 - accuracy: 0.7486 - val_loss: 1.0996 - val_accuracy: 0.6755\n",
      "Epoch 69/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 0.7059 - accuracy: 0.7663 - val_loss: 1.0903 - val_accuracy: 0.6656\n",
      "Epoch 70/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.7310 - accuracy: 0.7580 - val_loss: 1.0546 - val_accuracy: 0.6805\n",
      "Epoch 71/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.7574 - accuracy: 0.7484 - val_loss: 1.0007 - val_accuracy: 0.7003\n",
      "Epoch 72/75\n",
      "170/170 [==============================] - 246s 1s/step - loss: 0.7301 - accuracy: 0.7575 - val_loss: 1.0171 - val_accuracy: 0.7119\n",
      "Epoch 73/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.7209 - accuracy: 0.7576 - val_loss: 1.2657 - val_accuracy: 0.6672\n",
      "Epoch 74/75\n",
      "170/170 [==============================] - 248s 1s/step - loss: 0.6979 - accuracy: 0.7670 - val_loss: 1.0870 - val_accuracy: 0.6987\n",
      "Epoch 75/75\n",
      "170/170 [==============================] - 247s 1s/step - loss: 0.6885 - accuracy: 0.7711 - val_loss: 1.0954 - val_accuracy: 0.6921\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=75,\n",
    "                    validation_split=0.1,\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "670124e7472e2538ddd2fc0b2f30ccf441ee4c946a97eb23581fd7baa6ef010c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
